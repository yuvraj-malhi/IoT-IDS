{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_Central_Predictor.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2LIFoGMEhUT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3d7b789-2e40-4430-926c-cfd93af9cd11"
      },
      "source": [
        "from google.colab             import drive\n",
        "drive.mount ('/content/drive');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwuEhEGQFCVK",
        "cellView": "code",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c2d95be-8090-41ae-e449-78024a4b1b16"
      },
      "source": [
        "import shelve;\n",
        "import warnings;\n",
        "warnings.filterwarnings('ignore')\n",
        "import pandas            as pd;\n",
        "import numpy             as np;\n",
        "from sklearn.metrics          import balanced_accuracy_score,accuracy_score, f1_score, classification_report, precision_score, recall_score, precision_score, recall_score\n",
        "from sklearn.utils            import resample\n",
        "\n",
        "sh_file   = '/content/drive/MyDrive/Data/shelf_central'\n",
        "data_path = '/content/drive/MyDrive/Data/kddcup.data.corrected'\n",
        "\n",
        "\n",
        "########################## Test Becnh Setup ##########################\n",
        "print(\"\\n\\nSetting up test bench...\");\n",
        "\n",
        "############# Importing Models, scalers, encoders #############\n",
        "\n",
        "print(\"\\t> Importing trained models...\");\n",
        "shelver   = shelve.open(sh_file) \n",
        "\n",
        "for key in shelver:\n",
        "  globals()[key]=shelver[key]\n",
        "shelver.close()\n",
        "\n",
        "\n",
        "############# Defining a predictor pipeline function #############\n",
        "\n",
        "print(\"\\t> Creating 'PREDICTOR()' pipeline function...\");\n",
        "\n",
        "def PREDICTOR(data, verbose=1):\n",
        "  d = pd.DataFrame(data);\n",
        "  sh = d.shape;\n",
        "  if verbose==1:\n",
        "    print(\"\\n\\tPREDICTOR() called: {} Columns to predict!\".format(sh[0]));\n",
        "  if sh[1]==41:\n",
        "\n",
        "    # Column naming\n",
        "    for i in range(41):\n",
        "      d.rename(columns = {i: str(i)}, inplace = True) \n",
        "      \n",
        "    # Column division\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 Diving columns..\")\n",
        "    X_pred = d.iloc[:,:];\n",
        "\n",
        "    # Encoding categorical variables\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 Encoding..\")\n",
        "    X_pred = pd.DataFrame(IE.transform(X_pred));\n",
        "\n",
        "    # Scaling\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 Scaling..\")\n",
        "    X_pred = SCALE_IN.transform(X_pred);\n",
        "\n",
        "    # Dimensionality reduction with PCA\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 Reducing dimensions...\")\n",
        "    X_pred = DR.transform(X_pred);\n",
        "  \n",
        "    # Prediction\n",
        "    if verbose==1:  \n",
        "      print(\"\\t\\u2022 Random Forest Prediction...\")\n",
        "    Y_pred = MODEL.predict(X_pred);\n",
        "    \n",
        "    # Decoding\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 Decoding...\")\n",
        "    Y_ret = pd.DataFrame(TE.inverse_transform(Y_pred.astype(int)));\n",
        "\n",
        "    # Finding indexes of the 'object.' predictions\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 Finding indexes 'other.' indexes...\");\n",
        "    index = Y_ret.index;\n",
        "    condition = Y_ret[0] == 'other.'\n",
        "    idx_all = index[condition];\n",
        "\n",
        "    # Classifying 'object.' further\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 XGB Prediction...\")\n",
        "    for ind in idx_all:\n",
        "      X_ret = pd.DataFrame(d.iloc[[ind,0],:]);\n",
        "      X_ret = pd.DataFrame(IE.transform(X_ret));\n",
        "      Y_re  = MODEL2.predict(X_ret);\n",
        "      Y_re  = Y_re.astype(int)\n",
        "      Y_re  = pd.DataFrame(T2.inverse_transform(Y_re));\n",
        "      Y_ret[0][ind]=Y_re[0][0];\n",
        "\n",
        "    if verbose==1:\n",
        "      print(\"\\t\\u2022 PREDICTOR: Complete\\n\");\n",
        "    return pd.DataFrame(Y_ret);\n",
        "\n",
        "  else:\n",
        "    if verbose==1:\n",
        "      print(\"Error! Wrong format of input!\");\n",
        "    return 0;\n",
        "\n",
        "\n",
        "############# Defining an imbalance metrics calculator #############\n",
        "\n",
        "print(\"\\t> Creating 'METRIC()' imbalance metric calculator functions...\");\n",
        "\n",
        "def METRIC(Y_finalT,Y_finalP):\n",
        "  \n",
        "  acc = accuracy_score(Y_finalT,Y_finalP)\n",
        "  f1c = f1_score(Y_finalT,Y_finalP, average='macro')\n",
        "  prc = precision_score(Y_finalT,Y_finalP,average='macro');\n",
        "  rrc = recall_score(Y_finalT,Y_finalP, average = 'macro');\n",
        "  blc = balanced_accuracy_score(Y_finalT,Y_finalP);\n",
        "\n",
        "  print(\"\\t> Accuracy        - \"+str(acc));\n",
        "  print(\"\\t> F1 Score        - \"+str(f1c));\n",
        "  print(\"\\t> Precision       - \"+str(prc));\n",
        "  print(\"\\t> Recall          - \"+str(rrc));\n",
        "  print(\"\\t> Macro Accuracy  - \"+str(blc));\n",
        "\n",
        "############# Reading data file #############\n",
        "\n",
        "print(\"\\t> Reading file...\")\n",
        "df_backup        = pd.read_csv(data_path, header=None);\n",
        "\n",
        "########################## Test Bench ##########################\n",
        "print(\"\\n\\nTesing start\")\n",
        "\n",
        "\n",
        "############# SAMPLE 1 (random state 1) #############\n",
        "print(\"\\t\\n<> SAMPLE 1\");\n",
        "finalT = pd.DataFrame(df_backup .sample(n=40000, replace=False, random_state=1 ))\n",
        "\n",
        "X_finalT = pd.DataFrame(finalT.iloc[:,:-1]);\n",
        "Y_finalT = pd.DataFrame(finalT.iloc[:,-1]);\n",
        "Y_finalP = PREDICTOR(X_finalT)\n",
        "\n",
        "METRIC(Y_finalT,Y_finalP);\n",
        "\n",
        "############# SAMPLE 1 (random state 15) #############\n",
        "finalT = pd.DataFrame(df_backup .sample(n=40000, replace=False, random_state=2 ))\n",
        "\n",
        "print(\"\\t\\n<> SAMPLE 2\");\n",
        "X_finalT = pd.DataFrame(finalT.iloc[:,:-1]);\n",
        "Y_finalT = pd.DataFrame(finalT.iloc[:,-1]);\n",
        "Y_finalP = PREDICTOR(X_finalT)\n",
        "\n",
        "METRIC(Y_finalT,Y_finalP);\n",
        "\n",
        "\n",
        "############# SAMPLE 3 (random state 100) #############\n",
        "finalT = pd.DataFrame(df_backup .sample(n=40000, replace=False, random_state=3 ))\n",
        "\n",
        "print(\"\\t\\n<> SAMPLE 3\");\n",
        "X_finalT = pd.DataFrame(finalT.iloc[:,:-1]);\n",
        "Y_finalT = pd.DataFrame(finalT.iloc[:,-1]);\n",
        "Y_finalP = PREDICTOR(X_finalT)\n",
        "\n",
        "METRIC(Y_finalT,Y_finalP);\n",
        "\n",
        "print(\"\\n\\n\\t\\t\\t\\t THANK YOU\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Tesing start\n",
            "\t\n",
            "<> SAMPLE 1\n",
            "\n",
            "\tPREDICTOR() called: 40000 Columns to predict!\n",
            "\t• Diving columns..\n",
            "\t• Encoding..\n",
            "\t• Scaling..\n",
            "\t• Reducing dimensions...\n",
            "\t• Random Forest Prediction...\n",
            "\t• Decoding...\n",
            "\t• Finding indexes 'other.' indexes...\n",
            "\t• XGB Prediction...\n",
            "\t• PREDICTOR: Complete\n",
            "\n",
            "\t> Accuracy        - 0.9999\n",
            "\t> F1 Score        - 0.9331443666557784\n",
            "\t> Precision       - 0.9299835015527951\n",
            "\t> Recall          - 0.936501933250019\n",
            "\t> Macro Accuracy  - 0.9989353954666867\n",
            "\t\n",
            "<> SAMPLE 2\n",
            "\n",
            "\tPREDICTOR() called: 40000 Columns to predict!\n",
            "\t• Diving columns..\n",
            "\t• Encoding..\n",
            "\t• Scaling..\n",
            "\t• Reducing dimensions...\n",
            "\t• Random Forest Prediction...\n",
            "\t• Decoding...\n",
            "\t• Finding indexes 'other.' indexes...\n",
            "\t• XGB Prediction...\n",
            "\t• PREDICTOR: Complete\n",
            "\n",
            "\t> Accuracy        - 0.9998\n",
            "\t> F1 Score        - 0.9145404535144029\n",
            "\t> Precision       - 0.915841361389098\n",
            "\t> Recall          - 0.9138574912160793\n",
            "\t> Macro Accuracy  - 0.9900122821507525\n",
            "\t\n",
            "<> SAMPLE 3\n",
            "\n",
            "\tPREDICTOR() called: 40000 Columns to predict!\n",
            "\t• Diving columns..\n",
            "\t• Encoding..\n",
            "\t• Scaling..\n",
            "\t• Reducing dimensions...\n",
            "\t• Random Forest Prediction...\n",
            "\t• Decoding...\n",
            "\t• Finding indexes 'other.' indexes...\n",
            "\t• XGB Prediction...\n",
            "\t• PREDICTOR: Complete\n",
            "\n",
            "\t> Accuracy        - 0.99985\n",
            "\t> F1 Score        - 0.8517734599599155\n",
            "\t> Precision       - 0.8470622119815668\n",
            "\t> Recall          - 0.8570893325483059\n",
            "\t> Macro Accuracy  - 0.9999375546396903\n",
            "\n",
            "\n",
            "\t\t\t\t THANK YOU\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}